{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "project_dir = \"./\"\n",
    "data_dir = \"../Data/\"\n",
    "\n",
    "# (NOTE! this is taken from the official Cityscapes scripts:)\n",
    "Label = namedtuple( 'Label' , [\n",
    "\n",
    "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    'id'          , # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                    # during evaluations or not\n",
    "\n",
    "    'color'       , # The color of this label\n",
    "    ] )\n",
    "\n",
    "# (NOTE! this is taken from the official Cityscapes scripts:)\n",
    "labels = [\n",
    "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    Label(  'unlabeled'            ,  0 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'ego vehicle'          ,  1 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'rectification border' ,  2 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'out of roi'           ,  3 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'static'               ,  4 ,      19 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    Label(  'dynamic'              ,  5 ,      19 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    Label(  'ground'               ,  6 ,      19 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    Label(  'parking'              ,  9 ,      19 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    Label(  'rail track'           , 10 ,      19 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    Label(  'guard rail'           , 14 ,      19 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    Label(  'bridge'               , 15 ,      19 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    Label(  'tunnel'               , 16 ,      19 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    Label(  'polegroup'            , 18 ,      19 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
    "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    Label(  'caravan'              , 29 ,      19 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    Label(  'trailer'              , 30 ,      19 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
    "]\n",
    "\n",
    "# create a function mapping id to trainId:\n",
    "id_to_trainId = {label.id: label.trainId for label in labels}\n",
    "id_to_trainId_map_func = np.vectorize(id_to_trainId.get)\n",
    "\n",
    "new_img_height = 256 # (the height all images fed to the model will be resized to)\n",
    "new_img_width = 256 # (the width all images fed to the model will be resized to)\n",
    "no_of_classes = 20 # (number of object classes (road, sidewalk, car etc.))\n",
    "\n",
    "cityscapes_dir = data_dir + \"CityScapes/\"\n",
    "\n",
    "train_imgs_dir = cityscapes_dir + \"leftImg8bit_trainvaltest/leftImg8bit/train/\"\n",
    "train_gt_dir = cityscapes_dir + \"gtFine_trainvaltest/gtFine/train/\"\n",
    "\n",
    "val_imgs_dir = cityscapes_dir + \"leftImg8bit_trainvaltest/leftImg8bit/val/\"\n",
    "val_gt_dir = cityscapes_dir + \"gtFine_trainvaltest/gtFine/val/\"\n",
    "\n",
    "train_dirs = [\"jena/\", \"zurich/\", \"weimar/\", \"ulm/\", \"tubingen/\", \"stuttgart/\",\n",
    "            \"strasbourg/\", \"monchengladbach/\", \"krefeld/\", \"hanover/\",\n",
    "            \"hamburg/\", \"erfurt/\", \"dusseldorf/\", \"darmstadt/\", \"cologne/\",\n",
    "            \"bremen/\", \"bochum/\", \"aachen/\"]\n",
    "val_dirs = [\"frankfurt/\", \"munster/\", \"lindau/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abraham/anaconda3/envs/tf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512, 1024, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "img = cv2.imread(\"/home/abraham/Projects/ML/data/train_masks/aachen_000000_000019_trainId_label.png\",-1)\n",
    "img = to_categorical(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir 0/17, step 118/118\n",
      "train dir 1/17, step 121/121\n",
      "train dir 2/17, step 141/141\n",
      "train dir 3/17, step 94/94\n",
      "train dir 4/17, step 143/143\n",
      "train dir 5/17, step 195/195\n",
      "train dir 6/17, step 364/364\n",
      "train dir 7/17, step 93/93\n",
      "train dir 8/17, step 98/98\n",
      "train dir 9/17, step 195/195\n",
      "train dir 10/17, step 247/247\n",
      "train dir 11/17, step 108/108\n",
      "train dir 12/17, step 220/220\n",
      "train dir 13/17, step 84/84\n",
      "train dir 14/17, step 153/153\n",
      "train dir 15/17, step 315/315\n",
      "train dir 16/17, step 95/95\n",
      "train dir 17/17, step 173/173\n"
     ]
    }
   ],
   "source": [
    "# get the path to all training images and their corresponding label image:\n",
    "train_img_paths = []\n",
    "train_trainId_label_paths = []\n",
    "for dir_step, dir in enumerate(train_dirs):\n",
    "    img_dir = train_imgs_dir + dir\n",
    "\n",
    "    file_names = os.listdir(img_dir)\n",
    "    for step, file_name in enumerate(file_names):\n",
    "#         if step % 10 == 0:\n",
    "#             print(\"train dir %d/%d, step %d/%d\" % (dir_step, len(train_dirs)-1,\n",
    "#                         step, len(file_names)-1))\n",
    "\n",
    "        img_id = file_name.split(\"_left\")[0]\n",
    "\n",
    "        # read the image:\n",
    "        img_path = img_dir + file_name\n",
    "        img = cv2.imread(img_path, -1)\n",
    "\n",
    "        # resize the image without interpolation (want the image to still match\n",
    "        # the corresponding label image which we reisize below) and save to\n",
    "        # project_dir/data:\n",
    "        img_small = cv2.resize(img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "        img_small_path = project_dir + \"data/train_frames/\" + img_id + \".png\"\n",
    "        cv2.imwrite(img_small_path, img_small)\n",
    "        train_img_paths.append(img_small_path)\n",
    "\n",
    "        # read and resize the corresponding label image without interpolation\n",
    "        # (want the resulting image to still only contain pixel values\n",
    "        # corresponding to an object class):\n",
    "        gt_img_path = train_gt_dir + dir + img_id + \"_gtFine_labelIds.png\"\n",
    "        gt_img = cv2.imread(gt_img_path, -1)\n",
    "        gt_img_small = cv2.resize(gt_img, (new_img_width, new_img_height),\n",
    "                        interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # convert the label image from id to trainId pixel values:\n",
    "        id_label = gt_img_small\n",
    "        trainId_label = id_to_trainId_map_func(id_label)\n",
    "\n",
    "        # save the label image to project_dir/data:\n",
    "        trainId_label_path = project_dir + \"data/train_masks/\" + img_id + \"_trainId_label.png\"\n",
    "        cv2.imwrite(trainId_label_path, trainId_label)\n",
    "        train_trainId_label_paths.append(trainId_label_path)\n",
    "        \n",
    "    print(\"train dir %d/%d, step %d/%d\" % (dir_step, len(train_dirs)-1,\n",
    "                        step, len(file_names)-1))\n",
    "        \n",
    "# cPickle.dump(train_img_paths,\n",
    "#             open(project_dir + \"data/train_img_paths.pkl\", \"w\"))\n",
    "# cPickle.dump(train_trainId_label_paths,\n",
    "#             open(project_dir + \"data/train_trainId_label_paths.pkl\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean color channels of the train imgs:\n",
    "print(\"computing mean color channels of the train imgs\")\n",
    "no_of_train_imgs = len(train_img_paths)\n",
    "mean_channels = np.zeros((3, ))\n",
    "for step, img_path in enumerate(train_img_paths):\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "    img = cv2.imread(img_path, -1)\n",
    "\n",
    "    img_mean_channels = np.mean(img, axis=0)\n",
    "    img_mean_channels = np.mean(img_mean_channels, axis=0)\n",
    "\n",
    "    mean_channels += img_mean_channels\n",
    "\n",
    "mean_channels = mean_channels/float(no_of_train_imgs)\n",
    "\n",
    "# # save to disk:\n",
    "# cPickle.dump(mean_channels, open(project_dir + \"data/mean_channels.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing class weights\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-34cc9ae8d4f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# # save to disk:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"data/class_weights.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "# compute the class weights:\n",
    "print(\"computing class weights\")\n",
    "trainId_to_count = {}\n",
    "for trainId in range(no_of_classes):\n",
    "    trainId_to_count[trainId] = 0\n",
    "\n",
    "# # get the total number of pixels in all train labels that are of each\n",
    "# # object class:\n",
    "for step, trainId_label_path in enumerate(train_trainId_label_paths):\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "\n",
    "    # read the label image:\n",
    "    trainId_label = cv2.imread(trainId_label_path, -1)\n",
    "\n",
    "    for trainId in range(no_of_classes):\n",
    "        # count how many pixels in the label image are of object class trainId:\n",
    "        trainId_mask = np.equal(trainId_label, trainId)\n",
    "        label_trainId_count = np.sum(trainId_mask)\n",
    "\n",
    "        # add to the total count:\n",
    "        trainId_to_count[trainId] += label_trainId_count\n",
    "\n",
    "# # compute the class weights according to the paper:\n",
    "class_weights = []\n",
    "total_count = sum(trainId_to_count.values())\n",
    "for trainId, count in trainId_to_count.items():\n",
    "    trainId_prob = float(count)/float(total_count)\n",
    "    trainId_weight = 1/np.log(1.02 + trainId_prob)\n",
    "    class_weights.append(trainId_weight)\n",
    "\n",
    "# # save to disk:\n",
    "# cPickle.dump(class_weights, open(project_dir + \"data/class_weights.pkl\", \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dir 0/2, step 266/266\n",
      "val dir 1/2, step 173/173\n",
      "val dir 2/2, step 58/58\n"
     ]
    }
   ],
   "source": [
    "# get the path to all validation images and their corresponding label image:\n",
    "val_img_paths = []\n",
    "val_trainId_label_paths = []\n",
    "for dir_step, dir in enumerate(val_dirs):\n",
    "    img_dir = val_imgs_dir + dir\n",
    "\n",
    "    file_names = os.listdir(img_dir)\n",
    "    for step, file_name in enumerate(file_names):\n",
    "#         if step % 10 == 0:\n",
    "#             print(\"val dir %d/%d, step %d/%d\" % (dir_step, len(val_dirs)-1,\n",
    "#                         step, len(file_names)-1))\n",
    "\n",
    "        img_id = file_name.split(\"_left\")[0]\n",
    "\n",
    "        # read the image:\n",
    "        img_path = img_dir + file_name\n",
    "        img = cv2.imread(img_path, -1)\n",
    "\n",
    "        # resize the image without interpolation (want the image to still match\n",
    "        # the corresponding label image which we reisize below) and save to\n",
    "        # project_dir/data:\n",
    "        img_small = cv2.resize(img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "        img_small_path = project_dir + \"data/val_frames/\" + img_id + \".png\"\n",
    "        cv2.imwrite(img_small_path, img_small)\n",
    "        val_img_paths.append(img_small_path)\n",
    "\n",
    "        # read and resize the corresponding label image without interpolation\n",
    "        # (want the resulting image to still only contain pixel values\n",
    "        # corresponding to an object class):\n",
    "        gt_img_path = val_gt_dir + dir + img_id + \"_gtFine_labelIds.png\"\n",
    "        gt_img = cv2.imread(gt_img_path, -1)\n",
    "        gt_img_small = cv2.resize(gt_img, (new_img_width, new_img_height),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # convert the label image from id to trainId pixel values:\n",
    "        id_label = gt_img_small\n",
    "        trainId_label = id_to_trainId_map_func(id_label)\n",
    "\n",
    "        # save the label image to project_dir/data:\n",
    "        trainId_label_path = project_dir + \"data/val_masks/\" + img_id + \"_trainId_label.png\"\n",
    "        cv2.imwrite(trainId_label_path, trainId_label)\n",
    "        val_trainId_label_paths.append(trainId_label_path)\n",
    "        \n",
    "    print(\"val dir %d/%d, step %d/%d\" % (dir_step, len(val_dirs)-1,\n",
    "                        step, len(file_names)-1))\n",
    "\n",
    "# # save the validation data to disk:\n",
    "# cPickle.dump(val_trainId_label_paths,\n",
    "#             open(project_dir + \"data/val_trainId_label_paths.pkl\", \"w\"))\n",
    "# cPickle.dump(val_img_paths,\n",
    "#             open(project_dir + \"data/val_img_paths.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
